#!/usr/bin/env python3
"""
ComfyUI Rich Launcher - –∫—Ä–∞—Å–∏–≤—ã–π –∑–∞–ø—É—Å–∫ —Å —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –≤—ã–≤–æ–¥–æ–º
"""
import os
import sys
import subprocess
import re
import signal
import time
from pathlib import Path
from datetime import datetime

try:
    from rich.console import Console
    from rich.panel import Panel
    from rich.table import Table
    from rich.live import Live
    from rich.layout import Layout
    from rich.text import Text
    from rich.progress import Progress, SpinnerColumn, TextColumn
    from rich.syntax import Syntax
    from rich import box
except ImportError:
    print("‚ùå Rich library –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞. –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é...")
    subprocess.run([sys.executable, "-m", "pip", "install", "rich"], check=True)
    from rich.console import Console
    from rich.panel import Panel
    from rich.table import Table
    from rich.live import Live
    from rich.layout import Layout
    from rich.text import Text
    from rich.progress import Progress, SpinnerColumn, TextColumn
    from rich.syntax import Syntax
    from rich import box

console = Console()

# Detect GPU configuration
def detect_gpu_config():
    """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ GPU"""
    cuda_devices = os.environ.get('CUDA_VISIBLE_DEVICES', '')
    
    if not cuda_devices:
        return {
            'mode': 'cpu',
            'devices': [],
            'count': 0
        }
    
    devices = [d.strip() for d in cuda_devices.split(',') if d.strip()]
    
    return {
        'mode': 'dual' if len(devices) >= 2 else 'single',
        'devices': devices,
        'count': len(devices)
    }

GPU_CONFIG = detect_gpu_config()

# –°–æ—Å—Ç–æ—è–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏
loading_state = {
    "vram": None,
    "ram": None,
    "pytorch": None,
    "device": None,
    "python": None,
    "comfyui": None,
    "frontend": None,
    "port": None,
    "cuda_devices": None,
    "gpu_list": [],  # –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö GPU
    "last_log": "",
    "custom_nodes": [],
    "warnings": [],
    "errors": [],
    "server_started": False
}


def parse_log_line(line):
    """–ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä–æ–∫ –ª–æ–≥–∞ ComfyUI"""
    # VRAM info
    if "Total VRAM" in line:
        match = re.search(r"Total VRAM (\d+) MB, total RAM (\d+) MB", line)
        if match:
            loading_state["vram"] = int(match.group(1))
            loading_state["ram"] = int(match.group(2))
    
    # PyTorch version
    elif "pytorch version:" in line:
        match = re.search(r"pytorch version: ([\d.+\w]+)", line)
        if match:
            loading_state["pytorch"] = match.group(1)
    
    # Device info
    elif "Device:" in line:
        match = re.search(r"Device: (.+)", line)
        if match:
            loading_state["device"] = match.group(1).strip()
    
    # Python version
    elif "Python version:" in line:
        match = re.search(r"Python version: (.+)", line)
        if match:
            loading_state["python"] = match.group(1).strip()
    
    # ComfyUI version
    elif "ComfyUI version:" in line:
        match = re.search(r"ComfyUI version: ([\d.]+)", line)
        if match:
            loading_state["comfyui"] = match.group(1)
    
    # Frontend version
    elif "ComfyUI frontend version:" in line:
        match = re.search(r"ComfyUI frontend version: ([\d.]+)", line)
        if match:
            loading_state["frontend"] = match.group(1)
    
    # CUDA devices
    elif "CUDA_VISIBLE_DEVICES" in line:
        match = re.search(r"CUDA_VISIBLE_DEVICES[=:]?\s*(\S+)", line)
        if match:
            loading_state["cuda_devices"] = match.group(1)
    
    # Port
    elif "–ü–æ—Ä—Ç:" in line or "http://127.0.0.1:" in line:
        match = re.search(r"(\d{4,5})", line)
        if match:
            loading_state["port"] = match.group(1)
    
    # Server started
    elif "To see the GUI go to:" in line:
        loading_state["server_started"] = True
    
    # Custom nodes
    elif re.match(r"\s+[\d.]+ seconds: .+custom_nodes", line):
        match = re.search(r"([\d.]+) seconds: (.+)", line)
        if match:
            loading_state["custom_nodes"].append({
                "time": float(match.group(1)),
                "path": match.group(2).strip()
            })
    
    # Warnings
    elif "WARNING" in line or "Warning:" in line:
        loading_state["warnings"].append(line.strip())
    
    # Errors (–Ω–æ –Ω–µ –∫—Ä–∏—Ç–∏—á–Ω—ã–µ)
    elif "ERROR" in line and "DEPRECATION" not in line:
        loading_state["errors"].append(line.strip())
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –ª–æ–≥
    loading_state["last_log"] = line


def create_header_panel():
    """–°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞"""
    title = Text()
    title.append("üé® ", style="bold magenta")
    title.append("ComfyUI", style="bold cyan")
    title.append(" Launcher", style="bold white")
    
    subtitle = Text(f"Started at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}", style="dim")
    
    header = Text.assemble(title, "\n", subtitle)
    return Panel(header, box=box.DOUBLE, border_style="cyan")


def create_gpu_config_panel():
    """–°–æ–∑–¥–∞–Ω–∏–µ –ø–∞–Ω–µ–ª–∏ —Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π GPU"""
    if GPU_CONFIG['mode'] == 'cpu':
        text = Text("üñ•Ô∏è  CPU Mode", style="bold yellow")
        text.append("\nNo CUDA devices configured", style="dim")
        return Panel(text, title="GPU Configuration", border_style="yellow", box=box.ROUNDED)
    
    text = Text()
    
    # –†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã
    if GPU_CONFIG['mode'] == 'dual':
        text.append("üéÆ Dual GPU Mode\n", style="bold green")
        text.append(f"Using {GPU_CONFIG['count']} GPUs for distributed processing\n\n", style="dim")
    else:
        text.append("üéÆ Single GPU Mode\n", style="bold cyan")
        text.append(f"Using 1 GPU for processing\n\n", style="dim")
    
    # CUDA_VISIBLE_DEVICES
    cuda_devices = os.environ.get('CUDA_VISIBLE_DEVICES', 'not set')
    text.append("CUDA_VISIBLE_DEVICES: ", style="cyan")
    text.append(f"{cuda_devices}\n", style="yellow bold")
    
    # –°–ø–∏—Å–æ–∫ GPU –∏–∑ PyTorch (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)
    if loading_state["gpu_list"]:
        text.append("\nDetected GPUs:\n", style="cyan")
        for i, gpu_info in enumerate(loading_state["gpu_list"]):
            text.append(f"  GPU {i}: ", style="white")
            text.append(f"{gpu_info['name']}\n", style="green")
            text.append(f"         {gpu_info['memory']:.2f} GB VRAM\n", style="dim")
    
    border_color = "green" if GPU_CONFIG['mode'] == 'dual' else "cyan"
    return Panel(text, title="üéÆ GPU Configuration", border_style=border_color, box=box.ROUNDED)


def create_system_info_table():
    """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã —Å —Å–∏—Å—Ç–µ–º–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π"""
    table = Table(title="System Information", box=box.ROUNDED, border_style="green")
    table.add_column("Component", style="cyan", no_wrap=True)
    table.add_column("Value", style="yellow")
    
    if loading_state["python"]:
        table.add_row("üêç Python", loading_state["python"])
    
    if loading_state["pytorch"]:
        table.add_row("üî• PyTorch", loading_state["pytorch"])
    
    if loading_state["comfyui"]:
        table.add_row("üé® ComfyUI", loading_state["comfyui"])
    
    if loading_state["frontend"]:
        table.add_row("üåê Frontend", loading_state["frontend"])
    
    if loading_state["device"]:
        table.add_row("üéÆ Primary Device", loading_state["device"])
    
    if loading_state["vram"]:
        vram_gb = loading_state["vram"] / 1024
        table.add_row("üíæ Primary VRAM", f"{vram_gb:.2f} GB ({loading_state['vram']} MB)")
    
    if loading_state["ram"]:
        ram_gb = loading_state["ram"] / 1024
        table.add_row("üß† System RAM", f"{ram_gb:.2f} GB ({loading_state['ram']} MB)")
    
    if loading_state["port"]:
        url = f"http://127.0.0.1:{loading_state['port']}"
        table.add_row("üåê Server URL", url)
    
    return table


def create_custom_nodes_table():
    """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã —Å –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–º–∏ custom nodes"""
    if not loading_state["custom_nodes"]:
        return None
    
    table = Table(title="Custom Nodes", box=box.SIMPLE, border_style="blue")
    table.add_column("#", style="dim", width=3)
    table.add_column("Time", style="magenta", justify="right", width=8)
    table.add_column("Path", style="cyan")
    
    for idx, node in enumerate(loading_state["custom_nodes"][:10], 1):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10
        time_str = f"{node['time']:.1f}s"
        path = node['path'].replace('/media/zudva/git/git/ComfyUI/custom_nodes/', '')
        table.add_row(str(idx), time_str, path)
    
    if len(loading_state["custom_nodes"]) > 10:
        table.add_row("...", "...", f"... and {len(loading_state['custom_nodes']) - 10} more")
    
    return table


def create_warnings_panel():
    """–°–æ–∑–¥–∞–Ω–∏–µ –ø–∞–Ω–µ–ª–∏ —Å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è–º–∏"""
    if not loading_state["warnings"]:
        return None
    
    text = Text()
    for warning in loading_state["warnings"][:5]:  # –ü–µ—Ä–≤—ã–µ 5 –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π
        # –°–æ–∫—Ä–∞—â–∞–µ–º –¥–ª–∏–Ω–Ω—ã–µ –ø—É—Ç–∏
        warning = warning.replace('/media/zudva/git/git/ComfyUI/', '')
        text.append("‚ö†Ô∏è  ", style="yellow")
        text.append(warning[:100] + "...\n" if len(warning) > 100 else warning + "\n", style="dim")
    
    if len(loading_state["warnings"]) > 5:
        text.append(f"\n... and {len(loading_state['warnings']) - 5} more warnings", style="dim italic")
    
    return Panel(text, title="‚ö†Ô∏è  Warnings", border_style="yellow", box=box.ROUNDED)


def create_status_panel():
    """–°–æ–∑–¥–∞–Ω–∏–µ –ø–∞–Ω–µ–ª–∏ —Å—Ç–∞—Ç—É—Å–∞"""
    if loading_state["server_started"]:
        status = Text("‚úÖ Server is RUNNING", style="bold green")
        url = f"http://127.0.0.1:{loading_state['port']}" if loading_state["port"] else "http://127.0.0.1:8188"
        status.append(f"\n\nüåê Open: {url}", style="cyan underline")
        status.append("\n\nüí° Press Ctrl+C to stop", style="dim")
        return Panel(status, title="Status", border_style="green", box=box.HEAVY)
    else:
        dots = "." * ((int(time.time()) % 3) + 1)
        status = Text(f"‚è≥ Loading ComfyUI{dots}", style="bold yellow")
        if loading_state.get("last_log"):
            last = loading_state["last_log"]
            if len(last) > 100:
                last = last[:97] + "..."
            status.append(f"\n{last}", style="dim")
        return Panel(status, title="Status", border_style="yellow", box=box.HEAVY)


def display_dashboard():
    """–û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–π –ø–∞–Ω–µ–ª–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è"""
    console.clear()
    console.print(create_header_panel())
    console.print()
    
    # GPU –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
    console.print(create_gpu_config_panel())
    console.print()
    
    # –°–∏—Å—Ç–µ–º–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
    console.print(create_system_info_table())
    console.print()
    
    # Custom nodes
    nodes_table = create_custom_nodes_table()
    if nodes_table:
        console.print(nodes_table)
        console.print()
    
    # Warnings
    warnings_panel = create_warnings_panel()
    if warnings_panel:
        console.print(warnings_panel)
        console.print()
    
    # –°—Ç–∞—Ç—É—Å
    console.print(create_status_panel())


def render_loading_line():
    """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç—Ä–æ–∫–∏ —Å—Ç–∞—Ç—É—Å–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –±–µ–∑ –ø–æ–ª–Ω–æ–≥–æ —Ä–µ–¥–∏–∑–∞–π–Ω–∞"""
    dots = "." * ((int(time.time()) % 3) + 1)
    line = f"‚è≥ Loading ComfyUI{dots}"
    if loading_state.get("last_log"):
        last = loading_state["last_log"]
        if len(last) > 80:
            last = last[:77] + "..."
        line += f" | {last}"
    
    # –û—á–∏—â–∞–µ–º —Å—Ç—Ä–æ–∫—É –∏ –ø–µ—á–∞—Ç–∞–µ–º —Å –≤–æ–∑–≤—Ä–∞—Ç–æ–º –∫–∞—Ä–µ—Ç–∫–∏
    terminal_width = console.width
    padded_line = line.ljust(terminal_width)[:terminal_width]
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º print –Ω–∞–ø—Ä—è–º—É—é –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ \r
    import sys
    sys.stdout.write(f"\r{padded_line}")
    sys.stdout.flush()


def detect_gpus_via_torch():
    """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ GPU —á–µ—Ä–µ–∑ PyTorch"""
    try:
        root_dir = Path(__file__).parent
        venv_python = root_dir / ".venv" / "bin" / "python"
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º Python —Å–∫—Ä–∏–ø—Ç –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è GPU
        result = subprocess.run(
            [str(venv_python), "-c", 
             "import torch; import json; "
             "gpus = [{'name': torch.cuda.get_device_name(i), "
             "'memory': torch.cuda.get_device_properties(i).total_memory / 1024**3} "
             "for i in range(torch.cuda.device_count())]; "
             "print(json.dumps(gpus))"],
            capture_output=True,
            text=True,
            timeout=5,
            env=os.environ.copy()
        )
        
        if result.returncode == 0:
            import json
            return json.loads(result.stdout.strip())
    except Exception:
        pass
    
    return []


def run_comfyui(args):
    """–ó–∞–ø—É—Å–∫ ComfyUI —Å –ø–µ—Ä–µ—Ö–≤–∞—Ç–æ–º –≤—ã–≤–æ–¥–∞"""
    root_dir = Path(__file__).parent
    venv_python = root_dir / ".venv" / "bin" / "python"
    
    if not venv_python.exists():
        console.print("[red]‚ùå Python venv –Ω–µ –Ω–∞–π–¥–µ–Ω![/red]")
        console.print(f"–û–∂–∏–¥–∞–ª—Å—è: {venv_python}")
        sys.exit(1)
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º GPU —á–µ—Ä–µ–∑ PyTorch
    loading_state["gpu_list"] = detect_gpus_via_torch()
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–º–∞–Ω–¥—É
    cmd = [str(venv_python), "main.py"] + args
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å
    console.print("[cyan]üöÄ Starting ComfyUI...[/cyan]\n")
    
    process = subprocess.Popen(
        cmd,
        stdout=subprocess.PIPE,
        stderr=subprocess.STDOUT,
        text=True,
        bufsize=1,
        cwd=str(root_dir),
        env=os.environ.copy()
    )
    
    def signal_handler(sig, frame):
        console.print("\n[yellow]‚èπÔ∏è  Stopping ComfyUI...[/yellow]")
        process.terminate()
        try:
            process.wait(timeout=5)
        except subprocess.TimeoutExpired:
            process.kill()
        sys.exit(0)
    
    signal.signal(signal.SIGINT, signal_handler)
    
    loading_dashboard_shown = False
    started_dashboard_shown = False
    last_loading_inline = 0.0
    
    try:
        for line in process.stdout or []:
            line = line.rstrip()
            if not line:
                continue
            
            # –ü–∞—Ä—Å–∏–º —Å—Ç—Ä–æ–∫—É
            parse_log_line(line)
            
            # –ü–æ–∫–∞–∑–∞—Ç—å –æ–¥–∏–Ω —Ä–∞–∑ –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ –æ—Å–Ω–æ–≤–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            if not loading_dashboard_shown and loading_state["python"]:
                display_dashboard()
                loading_dashboard_shown = True

            # –§–∏–Ω–∞–ª—å–Ω—ã–π –ø–æ–∫–∞–∑ –ø–æ—Å–ª–µ —Å—Ç–∞—Ä—Ç–∞ —Å–µ—Ä–≤–µ—Ä–∞
            if loading_state["server_started"] and not started_dashboard_shown:
                display_dashboard()
                started_dashboard_shown = True

            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç—Ä–æ–∫—É –∑–∞–≥—Ä—É–∑–∫–∏ —Ç–æ—á–∫–∞–º–∏ –¥–æ —Å—Ç–∞—Ä—Ç–∞ —Å–µ—Ä–≤–µ—Ä–∞ (–Ω–µ –ø–µ—Ä–µ–ø–µ—á–∞—Ç—ã–≤–∞—è –≤–µ—Å—å —ç–∫—Ä–∞–Ω)
            if not loading_state["server_started"]:
                now_ts = time.time()
                if now_ts - last_loading_inline > 0.5:
                    render_loading_line()
                    last_loading_inline = now_ts
            
            # –¢–∞–∫–∂–µ –≤—ã–≤–æ–¥–∏–º —Å—ã—Ä–æ–π –ª–æ–≥ –≤ —Ñ–∞–π–ª –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
            # –ú–æ–∂–Ω–æ —Ä–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            # console.print(f"[dim]{line}[/dim]")
        
        process.wait()
        
    except KeyboardInterrupt:
        console.print("\n[yellow]‚èπÔ∏è  Interrupted by user[/yellow]")
        process.terminate()
        sys.exit(0)


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ä—Ç–æ–≤—É—é –∑–∞—Å—Ç–∞–≤–∫—É
    console.print(create_header_panel())
    console.print()
    
    # –ü–µ—Ä–µ–¥–∞–µ–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã –≤ ComfyUI
    args = sys.argv[1:]
    
    run_comfyui(args)


if __name__ == "__main__":
    main()
